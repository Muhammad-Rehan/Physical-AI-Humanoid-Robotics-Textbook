"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[4262],{249:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Introduction","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/intro/introduction","label":"Welcome to the AI Robotics Textbook!","docId":"intro/introduction","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Getting Started","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/getting-started/ros2-setup","label":"Setting up Your ROS 2 Environment","docId":"getting-started/ros2-setup","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 1: ROS 2","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module1-ros2/introduction","label":"Introduction to ROS 2","docId":"module1-ros2/introduction","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module1-ros2/python-agents-to-controllers","label":"Python Agents to ROS Controllers","docId":"module1-ros2/python-agents-to-controllers","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module1-ros2/understanding-urdf","label":"Understanding URDF (Unified Robot Description Format)","docId":"module1-ros2/understanding-urdf","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Simulation","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module2-gazebo/physics-simulation","label":"Simulating Physics in Gazebo","docId":"module2-gazebo/physics-simulation","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module2-gazebo/sensor-simulation","label":"Simulating Sensors (LiDAR, Depth Cameras)","docId":"module2-gazebo/sensor-simulation","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module2-gazebo/unity-rendering","label":"High-Fidelity Rendering in Unity","docId":"module2-gazebo/unity-rendering","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: Isaac & VSLAM","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module3-isaac/isaac-sim","label":"NVIDIA Isaac Sim and Synthetic Data Generation","docId":"module3-isaac/isaac-sim","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module3-isaac/vslam-navigation","label":"Hardware-accelerated VSLAM and Navigation","docId":"module3-isaac/vslam-navigation","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module3-isaac/path-planning-nav2","label":"Path Planning for Bipedal Humanoids with Nav2","docId":"module3-isaac/path-planning-nav2","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: VLA","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module4-vla/voice-to-action","label":"Voice-to-Action using OpenAI Whisper","docId":"module4-vla/voice-to-action","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module4-vla/cognitive-planning-llm","label":"Cognitive Planning with LLMs","docId":"module4-vla/cognitive-planning-llm","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Capstone Project","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module4-vla/capstone-project","label":"Capstone Project: The Autonomous Humanoid","docId":"module4-vla/capstone-project","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Resources","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Textbook/docs/resources/","label":"Resources","docId":"resources/resources","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"getting-started/ros2-setup":{"id":"getting-started/ros2-setup","title":"Setting up Your ROS 2 Environment","description":"Before diving into development, you need a functional ROS 2 environment. This section covers installation and basic tools.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Tutorial Intro","description":"Let\'s discover Docusaurus in less than 5 minutes."},"intro/introduction":{"id":"intro/introduction","title":"Welcome to the AI Robotics Textbook!","description":"Embark on a Journey to Build Autonomous Humanoids","sidebar":"tutorialSidebar"},"module1-ros2/introduction":{"id":"module1-ros2/introduction","title":"Introduction to ROS 2","description":"1.1 What is ROS 2?","sidebar":"tutorialSidebar"},"module1-ros2/python-agents-to-controllers":{"id":"module1-ros2/python-agents-to-controllers","title":"Python Agents to ROS Controllers","description":"This chapter focuses on integrating intelligent Python agents with ROS 2 to control robotic systems. We\'ll explore how to design and implement Python code that can interact with ROS 2 topics, services, and actions to command robots, process sensor data, and execute complex behaviors.","sidebar":"tutorialSidebar"},"module1-ros2/understanding-urdf":{"id":"module1-ros2/understanding-urdf","title":"Understanding URDF (Unified Robot Description Format)","description":"The Unified Robot Description Format (URDF) is an XML format for describing all aspects of a robot. It\'s a foundational tool in ROS 2 for representing your robot\'s physical structure, visual appearance, and collision properties. A URDF file allows ROS 2 to understand your robot\'s kinematic and dynamic properties, which is essential for simulation, visualization, motion planning, and more.","sidebar":"tutorialSidebar"},"module2-gazebo/physics-simulation":{"id":"module2-gazebo/physics-simulation","title":"Simulating Physics in Gazebo","description":"Gazebo is a powerful 3D robot simulator that is widely used in the robotics community. It allows for testing algorithms, designing robots, and performing regression testing without the need for physical hardware. A core strength of Gazebo is its realistic physics engine, which enables accurate simulation of robot dynamics and interactions with the environment.","sidebar":"tutorialSidebar"},"module2-gazebo/sensor-simulation":{"id":"module2-gazebo/sensor-simulation","title":"Simulating Sensors (LiDAR, Depth Cameras)","description":"Accurate sensor simulation is critical for developing and testing robotic perception, navigation, and control algorithms. Gazebo provides powerful capabilities to model a wide range of sensors, including LiDAR and depth cameras, allowing developers to work with realistic data without the need for physical hardware.","sidebar":"tutorialSidebar"},"module2-gazebo/unity-rendering":{"id":"module2-gazebo/unity-rendering","title":"High-Fidelity Rendering in Unity","description":"While Gazebo excels at physics simulation and ROS 2 integration, Unity offers unparalleled capabilities for high-fidelity rendering, realistic visualization, and advanced scene design. This makes Unity an excellent platform for tasks such as synthetic data generation for AI, user interface development, and visually rich simulations where aesthetic quality is paramount.","sidebar":"tutorialSidebar"},"module3-isaac/isaac-sim":{"id":"module3-isaac/isaac-sim","title":"NVIDIA Isaac Sim and Synthetic Data Generation","description":"NVIDIA Isaac Sim, built on the Omniverse platform, is a powerful robotics simulation and synthetic data generation tool designed to accelerate the development and deployment of AI-powered robots. It combines physically accurate simulation with photorealistic rendering, enabling developers to test algorithms in a high-fidelity virtual environment and generate vast amounts of diverse data for training deep learning models.","sidebar":"tutorialSidebar"},"module3-isaac/path-planning-nav2":{"id":"module3-isaac/path-planning-nav2","title":"Path Planning for Bipedal Humanoids with Nav2","description":"Path planning for bipedal humanoid robots presents unique challenges compared to wheeled or tracked robots. Humanoids must maintain balance, consider foot placement, and navigate complex environments with their distinct kinematics. Integrating these considerations with a powerful navigation framework like Nav2 requires careful adaptation and specialized approaches.","sidebar":"tutorialSidebar"},"module3-isaac/vslam-navigation":{"id":"module3-isaac/vslam-navigation","title":"Hardware-accelerated VSLAM and Navigation","description":"The NVIDIA Isaac platform significantly boosts robotic capabilities through hardware-accelerated processing, particularly in areas like Visual Simultaneous Localization and Mapping (VSLAM) and the ROS 2 Navigation Stack (Nav2). By offloading computationally intensive tasks to GPUs, Isaac ROS enables real-time performance that is crucial for autonomous navigation and dynamic environments.","sidebar":"tutorialSidebar"},"module4-vla/capstone-project":{"id":"module4-vla/capstone-project","title":"Capstone Project: The Autonomous Humanoid","description":"This capstone project serves as the culmination of the knowledge and skills acquired throughout this textbook. It challenges you to integrate various concepts from ROS 2 fundamentals, robot simulation (Gazebo, Unity, Isaac Sim), hardware-accelerated perception (Isaac ROS), and Vision-Language-Action (VLA) models to build an autonomous humanoid robot capable of understanding high-level voice commands and executing complex tasks in a simulated environment.","sidebar":"tutorialSidebar"},"module4-vla/cognitive-planning-llm":{"id":"module4-vla/cognitive-planning-llm","title":"Cognitive Planning with LLMs","description":"Large Language Models (LLMs) are transforming various domains, and robotics is no exception. Their ability to understand and generate human-like text, coupled with their vast encapsulated knowledge, makes them powerful tools for cognitive planning, enabling robots to interpret high-level commands and generate sequences of actions to achieve complex goals.","sidebar":"tutorialSidebar"},"module4-vla/voice-to-action":{"id":"module4-vla/voice-to-action","title":"Voice-to-Action using OpenAI Whisper","description":"Enabling robots to understand and act upon spoken commands is a significant step towards more natural and intuitive human-robot interaction. OpenAI Whisper, a powerful speech-to-text model, provides an excellent foundation for translating human voice instructions into machine-readable commands that a robot can then execute.","sidebar":"tutorialSidebar"},"resources/resources":{"id":"resources/resources","title":"Resources","description":"This section provides additional resources to deepen your understanding and assist in your journey through AI Robotics.","sidebar":"tutorialSidebar"},"tutorial-basics/congratulations":{"id":"tutorial-basics/congratulations","title":"Congratulations!","description":"You have just learned the basics of Docusaurus and made some changes to the initial template."},"tutorial-basics/create-a-blog-post":{"id":"tutorial-basics/create-a-blog-post","title":"Create a Blog Post","description":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed..."},"tutorial-basics/create-a-document":{"id":"tutorial-basics/create-a-document","title":"Create a Document","description":"Documents are groups of pages connected through:"},"tutorial-basics/create-a-page":{"id":"tutorial-basics/create-a-page","title":"Create a Page","description":"Add Markdown or React files to src/pages to create a standalone page:"},"tutorial-basics/deploy-your-site":{"id":"tutorial-basics/deploy-your-site","title":"Deploy your site","description":"Docusaurus is a static-site-generator (also called Jamstack)."},"tutorial-basics/markdown-features":{"id":"tutorial-basics/markdown-features","title":"Markdown Features","description":"Docusaurus supports Markdown and a few additional features."},"tutorial-extras/manage-docs-versions":{"id":"tutorial-extras/manage-docs-versions","title":"Manage Docs Versions","description":"Docusaurus can manage multiple versions of your docs."},"tutorial-extras/translate-your-site":{"id":"tutorial-extras/translate-your-site","title":"Translate your site","description":"Let\'s translate docs/intro.md to French."}}}}')}}]);